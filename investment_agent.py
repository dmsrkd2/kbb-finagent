import news_vector_store
import stock_data_analyzer
import hyperclova_llm
import pandas as pd
from typing import Dict, List
from datetime import datetime
import numpy as np
import time


from langchain.prompts import PromptTemplate
from langchain.text_splitter import RecursiveCharacterTextSplitter





class InvestmentAnalysisAgent:
    """ë­ì²´ì¸ ê¸°ë°˜ íˆ¬ì ë§¤ë§¤ë‚´ì—­ ë¶„ì„ AI Agent"""
    
    def __init__(self, hyperclova_api_key: str, google_api_key: str, google_search_engine_id: str):
        self.hyperclova_llm = hyperclova_llm.HyperCLOVAXLLM(api_key = hyperclova_api_key)
        self.news_vectorstore = news_vector_store.NewsVectorStore(api_key = hyperclova_api_key)
        self.google_searcher = news_vector_store.GoogleNewsSearcher(google_api_key, google_search_engine_id)
        self.news_crawler = news_vector_store.NewsContentCrawler()
        self.stock_analyzer = stock_data_analyzer.StockDataAnalyzer()
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200, # ë‹¤ìŒ ì²­í¬ì™€ ê²¹ì¹˜ëŠ” ë¶€ë¶„ ê¸¸ì´
            length_function=len
        )
        
        # ë¶„ì„ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        self.analysis_prompt = PromptTemplate(
            input_variables=["trade_info", "financial_metrics", "price_analysis", "relevant_news"],
            template="""ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ë§¤ë§¤ë‚´ì—­ì„ í† ëŒ€ë¡œ íˆ¬ì ìŠµê´€ì„ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì‚¬ìš©ìì˜ ë§¤ë§¤ë‚´ì—­ê³¼ í•´ë‹¹ ì‹œì ì˜ PER,PBR,ROE, ì£¼ê°€ ë°ì´í„°, ë‰´ìŠ¤ë¥¼ í† ëŒ€ë¡œ ì‚¬ìš©ìê°€ í•´ë‹¹ ì¢…ëª©ì„ ë§¤ìˆ˜, ë§¤ë„í•œ ê·¼ê±°ë¥¼ ì¶”ë¡ í•´ì„œ íˆ¬ììì˜ ë§¤ë§¤ ìŠµê´€ì„ ë¶„ì„í•˜ê³  í•´ë‹¹ ë§¤ë§¤ ë°©ì‹ì˜ ì¥ì , ì•½ì , ë¦¬ìŠ¤í¬, ë³´ì™„ë°©ë²• ë“±ì„ ë¶„ì„í•´ì„œ ë¦¬í¬íŠ¸ í˜•íƒœë¡œ ì œì¶œí•´ì¤˜.

## ë§¤ë§¤ ì •ë³´
{trade_info}

## ì¬ë¬´ ì§€í‘œ
{financial_metrics}

## ì£¼ê°€ ë¶„ì„
{price_analysis}

## ê´€ë ¨ ë‰´ìŠ¤
{relevant_news}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸í•œ íˆ¬ì ìŠµê´€ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”."""
        )
    
    def load_trading_data(self, csv_file_path: str) -> pd.DataFrame:
        """CSV íŒŒì¼ì—ì„œ ë§¤ë§¤ ë°ì´í„° ë¡œë“œ"""
        try:
            df = pd.read_csv(csv_file_path)
            df['Date'] = pd.to_datetime(df['Date'])
            return df
        except Exception as e:
            print(f"ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
            return pd.DataFrame()
    
    def get_or_fetch_news(self, symbol: str, date: str) -> List[Dict]:
        """ë‰´ìŠ¤ ê²€ìƒ‰ ë˜ëŠ” ìˆ˜ì§‘"""
        
        # 1. ê¸°ì¡´ ë²¡í„° DBì—ì„œ ê²€ìƒ‰
        query = f"{symbol} ì£¼ì‹ ë‰´ìŠ¤"
        existing_news = self.news_vectorstore.search_existing_news(symbol, date, query)
        
        if existing_news:
            print(f"âœ… ê¸°ì¡´ ë‰´ìŠ¤ ë°œê²¬: {len(existing_news)}ê°œ")
            return existing_news
        
        # 2. êµ¬ê¸€ ê²€ìƒ‰ APIë¡œ ìƒˆ ë‰´ìŠ¤ ìˆ˜ì§‘
        print(f"ğŸ” ìƒˆ ë‰´ìŠ¤ ê²€ìƒ‰: {symbol} - {date}")
        news_results = self.google_searcher.search_news(symbol, date)
        
        if not news_results:
            print("âŒ ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        # 3. ë‰´ìŠ¤ ë³¸ë¬¸ í¬ë¡¤ë§ ë° ì²˜ë¦¬
        processed_news = []
        for news in news_results[:3]:  # ìƒìœ„ 3ê°œë§Œ ì²˜ë¦¬
            print(f"ğŸ“° í¬ë¡¤ë§ ì¤‘: {news['title'][:50]}...")
            
            # ë³¸ë¬¸ í¬ë¡¤ë§
            content = self.news_crawler.crawl_news_content(news['url'])
            if not content:
                continue
            
            # í…ìŠ¤íŠ¸ ë¶„í• 
            chunks = self.text_splitter.split_text(content)

            
            # ë‰´ìŠ¤ ë°ì´í„° êµ¬ì„±
            news_data = {
                'symbol': symbol,
                'date': date,
                'title': news['title'],
                'url': news['url'],
                'source': news['source'],
                'content': content
            }
            
            # ë²¡í„° DBì— ì €ì¥
            if self.news_vectorstore.store_news_chunks(news_data, chunks):
                processed_news.append({
                    'title': news['title'],
                    'content': ' '.join(chunks[:3]),  # ìƒìœ„ 3ê°œ ì²­í¬ë§Œ
                    'relevance_score': self.calculate_relevance_score(content, symbol)
                })
            
            time.sleep(1)  # í¬ë¡¤ë§ ê°„ê²© ì¡°ì ˆ
        
        return processed_news
    
    def calculate_relevance_score(self, content: str, symbol: str) -> float:    # TODO relevance_score ë¡œì§ ë³€ê²½
        """ë‰´ìŠ¤ ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°"""
        positive_keywords = ['ìƒìŠ¹', 'ê¸‰ë“±', 'í˜¸ì¬', 'ë§¤ìˆ˜', 'íˆ¬ì', 'ì„±ì¥', 'ìˆ˜ìµ', 'ì¦ê°€']
        negative_keywords = ['í•˜ë½', 'ê¸‰ë½', 'ì•…ì¬', 'ë§¤ë„', 'ì†ì‹¤', 'ê°ì†Œ', 'ë¶€ì§„', 'ìœ„í—˜']
        
        content_lower = content.lower()
        
        positive_score = sum(1 for keyword in positive_keywords if keyword in content_lower)
        negative_score = sum(1 for keyword in negative_keywords if keyword in content_lower)
        symbol_mention = 2 if symbol.lower() in content_lower else 0
        
        return (positive_score + negative_score + symbol_mention) / 10
    
    def analyze_single_trade(self, trade_row: pd.Series) -> Dict:
        """ë‹¨ì¼ ë§¤ë§¤ ê±´ ë¶„ì„"""
        symbol = trade_row['Symbol']
        date = datetime.strptime(trade_row['Date'], '%Y-%m-%d')
        date = date.strftime('%Y-%m-%d')
        trade_type = trade_row['TradeType']
        price = trade_row['Price']
        quantity = trade_row['Quantity']
        
        print(f"\nğŸ“Š ë¶„ì„ ì¤‘: {symbol} - {date} ({trade_type})")
        
        # 1. ì¬ë¬´ ì§€í‘œ ê³„ì‚°
        financial_metrics = self.stock_analyzer.calculate_financial_metrics(symbol, date)
        
        # 2. ì£¼ê°€ ìœ„ì¹˜ ë¶„ì„
        price_analysis = self.stock_analyzer.analyze_price_position(symbol, date)
        
        # 3. ê´€ë ¨ ë‰´ìŠ¤ ìˆ˜ì§‘
        relevant_news = self.get_or_fetch_news(symbol, date)
        
        return {
            'symbol': symbol,
            'date': date,
            'trade_type': trade_type,
            'price': price,
            'quantity': quantity,
            'financial_metrics': financial_metrics,
            'price_analysis': price_analysis,
            'relevant_news': relevant_news
        }
    
    def generate_analysis_report(self, trade_analysis: Dict) -> str:    # ì—¬ê¸° ë‚˜ì¤‘ì— ì˜¤ë¥˜ ìƒê¸¸ë§Œ í•œë° ì–´ì§œí”¼ ë°”ê¿”ì•¼í•´ì„œ ëƒ…ë‘˜ê²Œ
        """LangChainì„ ì‚¬ìš©í•œ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        
        # ì…ë ¥ ë°ì´í„° í¬ë§·íŒ…
        trade_info = f"""
- ì¢…ëª©: {trade_analysis['symbol']}
- ë‚ ì§œ: {trade_analysis['date']}
- ë§¤ë§¤ ìœ í˜•: {trade_analysis['trade_type']}
- ê°€ê²©: {trade_analysis['price']:,.0f}ì›
- ìˆ˜ëŸ‰: {trade_analysis['quantity']}ì£¼
"""
        
        metrics = trade_analysis['financial_metrics']
        financial_metrics = f"""
- PER: {metrics['PER']:.2f}
- PBR: {metrics['PBR']:.2f}
- ROE: {metrics['ROE']:.2f}%
"""
        
        price_analysis = trade_analysis['price_analysis']
        price_info = f"""
- ê°€ê²© ìœ„ì¹˜: {price_analysis['position']} (ë°±ë¶„ìœ„: {price_analysis['percentile']:.1f}%)
- ë§¤ë§¤ê°€: {price_analysis.get('trade_price', 0):,.0f}ì›
- ê¸°ê°„ ìµœê³ ê°€: {price_analysis.get('high_price', 0):,.0f}ì›
- ê¸°ê°„ ìµœì €ê°€: {price_analysis.get('low_price', 0):,.0f}ì›
"""
        
        news_info = ""
        for i, news in enumerate(trade_analysis['relevant_news'][:3], 1):
            news_info += f"{i}. {news['title']}\n"
            news_info += f"   í‚¤ì›Œë“œ: {', '.join(news.get('keywords', [])[:5])}\n"
            news_info += f"   ê´€ë ¨ë„: {news.get('relevance_score', 0):.2f}\n\n"
        
        if not trade_analysis['relevant_news']:
            news_info = "í•´ë‹¹ ë‚ ì§œì— ê´€ë ¨ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„± ë° ì‹¤í–‰
        prompt = self.analysis_prompt.format(
            trade_info=trade_info,
            financial_metrics=financial_metrics,
            price_analysis=price_info,
            relevant_news=news_info
        )
        
        return self.hyperclova_llm._call(prompt)
    
    def analyze_trading_patterns(self, csv_file_path: str) -> str:
        """ì „ì²´ ë§¤ë§¤ íŒ¨í„´ ë¶„ì„"""
        
        # ë§¤ë§¤ ë°ì´í„° ë¡œë“œ
        trading_data = self.load_trading_data(csv_file_path)
        if trading_data.empty:
            return "ë§¤ë§¤ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        print(f"ğŸ“ˆ ì´ {len(trading_data)}ê±´ì˜ ë§¤ë§¤ ë°ì´í„° ë¶„ì„ ì‹œì‘...")
        
        # ê° ë§¤ë§¤ ê±´ë³„ ë¶„ì„
        analysis_results = []
        
        for idx, trade_row in trading_data.iterrows():
            try:
                # ë‹¨ì¼ ë§¤ë§¤ ë¶„ì„
                trade_analysis = self.analyze_single_trade(trade_row)
                
                # ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±
                analysis_report = self.generate_analysis_report(trade_analysis)
                
                analysis_results.append({
                    'trade_info': trade_analysis,
                    'analysis_report': analysis_report
                })
                
                print(f"âœ… ì™„ë£Œ: {idx+1}/{len(trading_data)}")
                
            except Exception as e:
                print(f"âŒ ë¶„ì„ ì˜¤ë¥˜ ({idx+1}): {e}")
                continue
        
        # ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±
        comprehensive_report = self.generate_comprehensive_report(analysis_results)
        
        return comprehensive_report
    
    def generate_comprehensive_report(self, analysis_results: List[Dict]) -> str:
        """ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        
        if not analysis_results:
            return "ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        report = f"""
# ğŸ¯ íˆ¬ì ìŠµê´€ ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸

## ğŸ“Š ê°œìš”
- ë¶„ì„ ê¸°ê°„: {len(analysis_results)}ê±´ì˜ ë§¤ë§¤ ë‚´ì—­
- ìƒì„± ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ“ˆ ë§¤ë§¤ íŒ¨í„´ ë¶„ì„
"""
        
        # ë§¤ë§¤ í†µê³„
        total_trades = len(analysis_results)
        buy_count = sum(1 for r in analysis_results if r['trade_info']['trade_type'] == 'Buy')
        sell_count = total_trades - buy_count
        
        # ì¢…ëª© ë¶„ì„
        symbols = [r['trade_info']['symbol'] for r in analysis_results]
        unique_symbols = list(set(symbols))
        symbol_counts = {symbol: symbols.count(symbol) for symbol in unique_symbols}
        
        report += f"""
### ë§¤ë§¤ í˜„í™©
- ì´ ë§¤ë§¤ ê±´ìˆ˜: {total_trades}ê±´
- ë§¤ìˆ˜: {buy_count}ê±´ ({buy_count/total_trades*100:.1f}%)
- ë§¤ë„: {sell_count}ê±´ ({sell_count/total_trades*100:.1f}%)

### ê±°ë˜ ì¢…ëª© í˜„í™©
- ê±°ë˜ ì¢…ëª© ìˆ˜: {len(unique_symbols)}ê°œ
- ì£¼ìš” ê±°ë˜ ì¢…ëª©:
"""
        
        # ìƒìœ„ ê±°ë˜ ì¢…ëª©
        sorted_symbols = sorted(symbol_counts.items(), key=lambda x: x[1], reverse=True)
        for symbol, count in sorted_symbols[:5]:
            report += f"  - {symbol}: {count}ê±´\n"
        
        # ê°€ê²© ìœ„ì¹˜ ë¶„ì„
        price_positions = [r['trade_info']['price_analysis']['position'] for r in analysis_results]
        high_count = price_positions.count('high')
        middle_count = price_positions.count('middle')
        low_count = price_positions.count('low')
        
        report += f"""
### ë§¤ë§¤ ì‹œì  ë¶„ì„
- ê³ ê°€ê¶Œ ë§¤ë§¤: {high_count}ê±´ ({high_count/total_trades*100:.1f}%)
- ì¤‘ê°„ê¶Œ ë§¤ë§¤: {middle_count}ê±´ ({middle_count/total_trades*100:.1f}%)
- ì €ê°€ê¶Œ ë§¤ë§¤: {low_count}ê±´ ({low_count/total_trades*100:.1f}%)
"""
        
        # ê°œë³„ ë§¤ë§¤ ë¶„ì„ ìš”ì•½
        report += "\n## ğŸ“ ê°œë³„ ë§¤ë§¤ ë¶„ì„\n\n"
        
        for i, result in enumerate(analysis_results, 1):
            trade_info = result['trade_info']
            report += f"### {i}. {trade_info['symbol']} - {trade_info['date']} ({trade_info['trade_type']})\n"
            report += f"**ê°€ê²©:** {trade_info['price']:,.0f}ì› / **ìˆ˜ëŸ‰:** {trade_info['quantity']}ì£¼\n"
            report += f"**ìœ„ì¹˜:** {trade_info['price_analysis']['position']} (ë°±ë¶„ìœ„: {trade_info['price_analysis']['percentile']:.1f}%)\n"
            report += f"**ì¬ë¬´ì§€í‘œ:** PER {trade_info['financial_metrics']['PER']:.2f}, "
            report += f"PBR {trade_info['financial_metrics']['PBR']:.2f}, "
            report += f"ROE {trade_info['financial_metrics']['ROE']:.2f}%\n"
            
            if trade_info['relevant_news']:
                report += f"**ê´€ë ¨ ë‰´ìŠ¤:** {len(trade_info['relevant_news'])}ê±´\n"
            
            report += "\n**ë¶„ì„ ê²°ê³¼:**\n"
            report += result['analysis_report']
            report += "\n" + "="*50 + "\n\n"
        
        # ì¢…í•© íˆ¬ì ìŠµê´€ ë¶„ì„
        comprehensive_analysis = self.generate_final_comprehensive_analysis(analysis_results)
        report += f"\n## ğŸ¯ ì¢…í•© íˆ¬ì ìŠµê´€ ë¶„ì„\n\n{comprehensive_analysis}"
        
        return report
    
    def generate_final_comprehensive_analysis(self, analysis_results: List[Dict]) -> str:
        """ìµœì¢… ì¢…í•© ë¶„ì„"""
        
        # ì „ì²´ ë§¤ë§¤ íŒ¨í„´ ìš”ì•½
        patterns_summary = self.summarize_trading_patterns(analysis_results)
        
        # ì¢…í•© ë¶„ì„ í”„ë¡¬í”„íŠ¸
        comprehensive_prompt = f"""
ë‹¹ì‹ ì€ íˆ¬ì ì „ë¬¸ê°€ë¡œì„œ ë‹¤ìŒê³¼ ê°™ì€ ë§¤ë§¤ íŒ¨í„´ ë¶„ì„ ê²°ê³¼ë¥¼ í† ëŒ€ë¡œ íˆ¬ììì˜ ì „ë°˜ì ì¸ íˆ¬ì ìŠµê´€ì„ ì¢…í•© ë¶„ì„í•´ì£¼ì„¸ìš”:

## ë§¤ë§¤ íŒ¨í„´ ìš”ì•½
{patterns_summary}

## ê°œë³„ ë§¤ë§¤ ë¶„ì„ ê²°ê³¼
{self.extract_key_insights(analysis_results)}

ìœ„ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ë‹¤ìŒ ê´€ì ì—ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. **íˆ¬ì ìŠ¤íƒ€ì¼ ë¶„ì„** - ê°€ì¹˜íˆ¬ì, ì„±ì¥íˆ¬ì, ê¸°ìˆ ì  ë¶„ì„ ë“± ì–´ë–¤ ìŠ¤íƒ€ì¼ì¸ì§€
2. **ë§¤ë§¤ íƒ€ì´ë° ë¶„ì„** - ê³ ì /ì €ì  ë§¤ë§¤ íŒ¨í„´, ì‹œì¥ íƒ€ì´ë° ëŠ¥ë ¥
3. **ì¢…ëª© ì„ íƒ ê¸°ì¤€** - ì–´ë–¤ ê¸°ì¤€ìœ¼ë¡œ ì¢…ëª©ì„ ì„ íƒí•˜ëŠ”ì§€ ì¶”ë¡ 
4. **ë¦¬ìŠ¤í¬ ê´€ë¦¬** - í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì‚°, ì†ì ˆ/ìµì ˆ íŒ¨í„´
5. **ê°•ì ê³¼ ì•½ì ** - í˜„ì¬ íˆ¬ì ë°©ì‹ì˜ ì¥ë‹¨ì 
6. **ê°œì„  ë°©ì•ˆ** - êµ¬ì²´ì ì¸ ê°œì„  ì œì•ˆ

ë¶„ì„ ê²°ê³¼ë¥¼ ì²´ê³„ì ì´ê³  ì‹¤ìš©ì ìœ¼ë¡œ ì œì‹œí•´ì£¼ì„¸ìš”.
"""
        
        return self.hyperclova_llm._call(comprehensive_prompt)
    
    def summarize_trading_patterns(self, analysis_results: List[Dict]) -> str:
        """ë§¤ë§¤ íŒ¨í„´ ìš”ì•½"""
        
        total_trades = len(analysis_results)
        
        # ë§¤ë§¤ íƒ€ì…ë³„ ë¶„ì„
        buy_trades = [r for r in analysis_results if r['trade_info']['trade_type'] == 'Buy']
        sell_trades = [r for r in analysis_results if r['trade_info']['trade_type'] == 'Sell']
        
        # ê°€ê²© ìœ„ì¹˜ ë¶„ì„
        buy_positions = [r['trade_info']['price_analysis']['position'] for r in buy_trades]
        sell_positions = [r['trade_info']['price_analysis']['position'] for r in sell_trades]
        
        # ì¬ë¬´ì§€í‘œ ë¶„ì„
        avg_per = np.mean([r['trade_info']['financial_metrics']['PER'] for r in analysis_results if r['trade_info']['financial_metrics']['PER'] > 0])
        avg_pbr = np.mean([r['trade_info']['financial_metrics']['PBR'] for r in analysis_results if r['trade_info']['financial_metrics']['PBR'] > 0])
        avg_roe = np.mean([r['trade_info']['financial_metrics']['ROE'] for r in analysis_results if r['trade_info']['financial_metrics']['ROE'] > 0])
        
        summary = f"""
### ë§¤ë§¤ íŒ¨í„´ í†µê³„
- ì´ ë§¤ë§¤: {total_trades}ê±´
- ë§¤ìˆ˜: {len(buy_trades)}ê±´, ë§¤ë„: {len(sell_trades)}ê±´

### ë§¤ìˆ˜ íŒ¨í„´
- ê³ ê°€ê¶Œ ë§¤ìˆ˜: {buy_positions.count('high')}ê±´
- ì¤‘ê°„ê¶Œ ë§¤ìˆ˜: {buy_positions.count('middle')}ê±´  
- ì €ê°€ê¶Œ ë§¤ìˆ˜: {buy_positions.count('low')}ê±´

### ë§¤ë„ íŒ¨í„´
- ê³ ê°€ê¶Œ ë§¤ë„: {sell_positions.count('high')}ê±´
- ì¤‘ê°„ê¶Œ ë§¤ë„: {sell_positions.count('middle')}ê±´
- ì €ê°€ê¶Œ ë§¤ë„: {sell_positions.count('low')}ê±´

### í‰ê·  ì¬ë¬´ì§€í‘œ
- í‰ê·  PER: {avg_per:.2f}
- í‰ê·  PBR: {avg_pbr:.2f}
- í‰ê·  ROE: {avg_roe:.2f}%
"""
        
        return summary
    
    def extract_key_insights(self, analysis_results: List[Dict]) -> str:
        """í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ"""
        
        insights = []
        
        for result in analysis_results:
            trade_info = result['trade_info']
            analysis = result['analysis_report']
            
            # ì£¼ìš” íŠ¹ì§• ì¶”ì¶œ
            key_features = {
                'symbol': trade_info['symbol'],
                'trade_type': trade_info['trade_type'],
                'price_position': trade_info['price_analysis']['position'],
                'per': trade_info['financial_metrics']['PER'],
                'news_count': len(trade_info['relevant_news'])
            }
            
            insights.append(key_features)
        
        # ì¸ì‚¬ì´íŠ¸ ìš”ì•½
        summary = "ì£¼ìš” ë§¤ë§¤ íŠ¹ì§•:\n"
        for i, insight in enumerate(insights, 1):
            summary += f"{i}. {insight['symbol']} {insight['trade_type']} - "
            summary += f"{insight['price_position']}ê°€ê¶Œ, PER {insight['per']:.1f}, "
            summary += f"ë‰´ìŠ¤ {insight['news_count']}ê±´\n"
        
        return summary
    
    def save_analysis_report(self, report: str, filename: str = None) -> str:
        """ë¶„ì„ ë¦¬í¬íŠ¸ ì €ì¥"""
        
        if filename is None:
            filename = f"investment_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(report)
            print(f"âœ… ë¶„ì„ ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: {filename}")
            return filename
        except Exception as e:
            print(f"âŒ ë¦¬í¬íŠ¸ ì €ì¥ ì˜¤ë¥˜: {e}")
            return ""
